{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# بسم الله الرحمن الرحيم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"img/red_panda.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Gray panda\", gray_image)\n",
    "cv2.imshow(\"Red panda\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save image\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"img/red_panda.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imwrite(\"out/gray_panda.jpg\", gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from Webcam\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Ret is just equal to True or False. It’s true if cap is reading a frame, \n",
    "    # and frame is the the array containing the image.\n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from File\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"vid/red_panda_snow.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(25)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Video from file and Save it to file\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"vid/red_panda_snow.mp4\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "out = cv2.VideoWriter(\"out/flipped_red_panda.avi\", fourcc, 25, (640, 360))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame2 = cv2.flip(frame, 1)\n",
    "    \n",
    "    cv2.imshow(\"frame2\", frame2)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    out.write(frame2)\n",
    "    \n",
    "    key = cv2.waitKey(25)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# Drawing and Writing on images\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "image = cv2.imread(\"img/red_panda.jpg\")\n",
    "shape = image.shape\n",
    "print(shape)\n",
    " \n",
    "blue = (255, 0, 0)\n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "violet = (180, 0, 180)\n",
    "yellow = (0, 180, 180)\n",
    "white = (255, 255, 255)\n",
    " \n",
    "cv2.line(image, (50, 30), (450, 35), blue, thickness=5)\n",
    "cv2.circle(image, (240, 205), 23, red, -1)\n",
    "cv2.rectangle(image, (50, 60), (450, 95), green, -1)\n",
    "cv2.ellipse(image, (250, 150), (80, 20), 5, 0, 360, violet, -1)\n",
    "points = np.array([[[140, 230], [380, 230], [320, 250], [250, 280]]], np.int32)\n",
    "cv2.polylines(image, [points], True, yellow, thickness=3)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(image, \"Panda\", (20, 180), font, 4, white)\n",
    " \n",
    "cv2.imshow(\"red panda\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic operations on images\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "image = cv2.imread(\"img/red_panda.jpg\")\n",
    "rows, cols, ch = image.shape\n",
    "\n",
    "# roi = Region of Interest \n",
    "roi = image[100: 280, 150: 320]\n",
    " \n",
    "cv2.imshow(\"Panda\", image)\n",
    "cv2.imshow(\"Roi\", roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149 144 143]\n",
      "[255 255 255]\n",
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "# Add images and Threshold\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img1 = cv2.imread(\"img/road.jpg\")\n",
    "img2 = cv2.imread(\"img/car.jpg\")\n",
    "\n",
    "cv2.imshow(\"img1\", img1) # original image\n",
    "cv2.imshow(\"img2\", img2) # original image\n",
    "\n",
    "# To add the images, they must have the same size\n",
    "wrong_sum = cv2.add(img1, img2)\n",
    "cv2.imshow(\"wrong sum\", wrong_sum)\n",
    "\n",
    "# Why is it wrong?\n",
    "# We take the sum of the pixels - pixel by pixel\n",
    "print(img1[0, 0]) # 1st pixel\n",
    "print(img2[0, 0]) # 1st pixel\n",
    "print(wrong_sum[0,0])\n",
    "\n",
    "# Better way to add images\n",
    "# weighted sum\n",
    "weighted = cv2.addWeighted(img1, 1, img2, 0.1, 0)\n",
    "\n",
    "# Remove white background\n",
    "# step 01: convert image to gray\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "# Note: Lights color has changed from orange to white\n",
    "cv2.imshow(\"img2gray\", img2_gray)\n",
    "\n",
    "#Simple Thresholding\n",
    "# Here, the matter is straight forward. \n",
    "# If pixel value is greater than a threshold value, it is assigned one value (may be white), \n",
    "# else it is assigned another value (may be black). \n",
    "# The function used is cv2.threshold. \n",
    "# First argument is the source image, which should be a grayscale image. \n",
    "# Second argument is the threshold value which is used to classify the pixel values. \n",
    "# Third argument is the maxVal which represents the value to be given if pixel value is more than \n",
    "# (sometimes less than) the threshold value. \n",
    "# OpenCV provides different styles of thresholding and it is decided by the fourth parameter of the function\n",
    "\n",
    "# step 02: Define threshold\n",
    "# all values greater than 0 will be 255\n",
    "# any pixel with value larger than 0 will be white\n",
    "# else, pixel will be black, because we are using threshold binary\n",
    "ret, threshold = cv2.threshold(img2_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"threshold\", threshold)\n",
    "\n",
    "# Here, all values greater than 240 will be white\n",
    "# else, they will be black, because we are using threshold binary\n",
    "ret, mod2_threshold = cv2.threshold(img2_gray, 240, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"mod2 threshold\", mod2_threshold)\n",
    "\n",
    "# threshold binary inverted\n",
    "ret, mask = cv2.threshold(img2_gray, 252, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"mask\", mask)\n",
    "\n",
    "sum = cv2.add(img2, img2, mask=mask)\n",
    " \n",
    "cv2.imshow(\"sum\", sum)\n",
    "cv2.imshow(\"threshold\", mask)\n",
    "cv2.imshow(\"weighted\", weighted)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blending Images\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img1 = cv2.imread(\"img/road.jpg\")\n",
    "img2 = cv2.imread(\"img/car.jpg\")\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "ret, mask = cv2.threshold(img2_gray, 240, 255, cv2.THRESH_BINARY)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    " \n",
    "road = cv2.bitwise_and(img1, img1, mask=mask)\n",
    "car = cv2.bitwise_and(img2, img2, mask=mask_inv)\n",
    "result = cv2.add(road, car)\n",
    " \n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.imshow(\"road background\", road)\n",
    "cv2.imshow(\"car no background\", car)\n",
    "cv2.imshow(\"mask\", mask)\n",
    "cv2.imshow(\"mask inverse\", mask_inv)\n",
    "cv2.imshow(\"result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitwise Operators\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img1 = cv2.imread(\"img/drawing_1.png\")\n",
    "img2 = cv2.imread(\"img/drawing_2.png\")\n",
    " \n",
    "bit_and = cv2.bitwise_and(img2, img1)\n",
    "\n",
    "# white or black -> white\n",
    "bit_or = cv2.bitwise_or(img2, img1)\n",
    "\n",
    "bit_xor = cv2.bitwise_xor(img1, img2)\n",
    "bit_not = cv2.bitwise_not(img1)\n",
    "bit_not2 = cv2.bitwise_not(img2)\n",
    " \n",
    " \n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    " \n",
    "cv2.imshow(\"bit_and\", bit_and)\n",
    "cv2.imshow(\"bit_or\", bit_or)\n",
    "cv2.imshow(\"bit_xor\", bit_xor)\n",
    "cv2.imshow(\"bit_not\", bit_not)\n",
    "cv2.imshow(\"bit_not2\", bit_not2)\n",
    " \n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trackbars\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# something for C++ - Maybe\n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "cv2.namedWindow(\"frame\")\n",
    "cv2.createTrackbar(\"test\", \"frame\", 50, 500, nothing)\n",
    "cv2.createTrackbar(\"color/gray\", \"frame\", 0, 1, nothing)\n",
    " \n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    " \n",
    "    test = cv2.getTrackbarPos(\"test\", \"frame\")\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    cv2.putText(frame, str(test), (50, 150), font, 4, (0, 0, 255))\n",
    " \n",
    "    s = cv2.getTrackbarPos(\"color/gray\", \"frame\")\n",
    "    if s == 0:\n",
    "        pass\n",
    "    else:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    cv2.imshow(\"frame\", frame)\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Detection using HSV\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    " \n",
    "cv2.createTrackbar(\"L - H\", \"Trackbars\", 0, 179, nothing)\n",
    "cv2.createTrackbar(\"L - S\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"L - V\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"U - H\", \"Trackbars\", 179, 179, nothing)\n",
    "cv2.createTrackbar(\"U - S\", \"Trackbars\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"U - V\", \"Trackbars\", 255, 255, nothing)\n",
    " \n",
    " \n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    " \n",
    "    # Low and High\n",
    "    # Because we take a range of values, not only a single value\n",
    "    # To avoid lightening effect, etc.\n",
    "\n",
    "    l_h = cv2.getTrackbarPos(\"L - H\", \"Trackbars\")\n",
    "    l_s = cv2.getTrackbarPos(\"L - S\", \"Trackbars\")\n",
    "    l_v = cv2.getTrackbarPos(\"L - V\", \"Trackbars\")\n",
    "    u_h = cv2.getTrackbarPos(\"U - H\", \"Trackbars\")\n",
    "    u_s = cv2.getTrackbarPos(\"U - S\", \"Trackbars\")\n",
    "    u_v = cv2.getTrackbarPos(\"U - V\", \"Trackbars\")\n",
    " \n",
    "    lower_color = np.array([l_h, l_s, l_v])\n",
    "    upper_color = np.array([u_h, u_s, u_v])\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    " \n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    " \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"result\", result)\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Thresholding\n",
    "# Demo 01\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"img/black_to_white.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    " \n",
    "_, threshold_binary = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
    "_, threshold_binary_inv = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "# values above threshold will be truncated to the threshold, but values below it will keep their values\n",
    "_, threshold_trunc = cv2.threshold(img, 128, 255, cv2.THRESH_TRUNC)\n",
    "# values below threshold will be set to zero\n",
    "_, threshold_to_zero = cv2.threshold(img, 128, 255, cv2.THRESH_TOZERO)\n",
    " \n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"th binary\", threshold_binary)\n",
    "cv2.imshow(\"th binary inv\", threshold_binary_inv)\n",
    "cv2.imshow(\"th trunc\", threshold_trunc)\n",
    "cv2.imshow(\"th to zero\", threshold_to_zero)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold with Trackbar\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "img = cv2.imread(\"img/red_panda.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.createTrackbar(\"Threshold value\", \"Image\", 128, 255, nothing)\n",
    " \n",
    " \n",
    "while True:\n",
    "    value_threshold = cv2.getTrackbarPos(\"Threshold value\", \"Image\")\n",
    "    _, threshold_binary = cv2.threshold(img, value_threshold, 255, cv2.THRESH_BINARY)\n",
    "    _, threshold_binary_inv = cv2.threshold(img, value_threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    _, threshold_trunc = cv2.threshold(img, value_threshold, 255, cv2.THRESH_TRUNC)\n",
    "    _, threshold_to_zero = cv2.threshold(img, value_threshold, 255, cv2.THRESH_TOZERO)\n",
    "    _, threshold_to_zero_inv = cv2.threshold(img, value_threshold, 255, cv2.THRESH_TOZERO_INV)\n",
    " \n",
    " \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.imshow(\"th binary\", threshold_binary)\n",
    "    cv2.imshow(\"th binary inv\", threshold_binary_inv)\n",
    "    cv2.imshow(\"th trunc\", threshold_trunc)\n",
    "    cv2.imshow(\"th to zero\", threshold_to_zero)\n",
    "    cv2.imshow(\"th to zero inv\", threshold_to_zero_inv)\n",
    " \n",
    "    key = cv2.waitKey(100)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = cv2.imread(\"img/red_panda.jpg\")\n",
    "b, g, r = cv2.split(img)\n",
    " \n",
    "# cv2.imshow(\"img\", img)\n",
    "# cv2.imshow(\"b\", b)\n",
    "# cv2.imshow(\"g\", g)\n",
    "# cv2.imshow(\"r\", r)\n",
    " \n",
    "plt.hist(b.ravel(), 256, [0, 256])\n",
    "plt.hist(g.ravel(), 256, [0, 256])\n",
    "plt.hist(r.ravel(), 256, [0, 256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digital Image Transformations\n",
    "\n",
    "### Kernel\n",
    "In image processing, a kernel, convolution matrix, or mask is a small matrix. \n",
    "- It is used for blurring, sharpening, embossing, edge detection, and more. \n",
    "- This is accomplished by doing a convolution between a kernel and an image. \n",
    "The general expression of a convolution is \n",
    "\n",
    "<img src=\"imgs/kernel_01.svg\" >\n",
    "\n",
    "where g ( x , y ) is the filtered image, f ( x , y ) is the original image, ω is the filter kernel. Every element of the filter kernel is considered by − a ≤ s ≤ a and − b ≤ t ≤ b .\n",
    "\n",
    "| Operation                                                                                                      | Kernel                                                      |  Image Result                                                       |\n",
    "|----------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------|---------------------------------------------------------------------|\n",
    "| Identity                                                                                                       | <img src=\"imgs/kernel_identity.svg\" />                      | <img src=\"imgs/kernel_identity_result.png\" />                       |\n",
    "| Edge Detection                                                                                                 | <img src=\"imgs/kernel_edge_detection_01.svg\" />             | <img src=\"imgs/kernel_edge_detection_01_result.png\" />              |\n",
    "| Edge Detection                                                                                                 | <img src=\"imgs/kernel_edge_detection_02.svg\" />             | <img src=\"imgs/kernel_edge_detection_02_result.png\" />              |\n",
    "| Edge Detection                                                                                                 | <img src=\"imgs/kernel_edge_detection_03.svg\" />             | <img src=\"imgs/kernel_edge_detection_03_result.png\" />              |\n",
    "| Sharpen                                                                                                        | <img src=\"imgs/kernel_sharpen.svg\" />                       | <img src=\"imgs/kernel_sharpen_result.png\" />                        |\n",
    "| Box Blur (normalized)                                                                                          | <img src=\"imgs/kernel_box_blur.svg\" />                      | <img src=\"imgs/kernel_box_blur_result.png\" />                       |\n",
    "| Gaussian Blur (3 x 3) Approximation                                                                            | <img src=\"imgs/kernel_gaussian_blur_approximation_3.svg\" /> | <img src=\"imgs/kernel_gaussian_blur_approximation_3_result.png\" />  |\n",
    "| Gaussian Blur (5 x 5) Approximation                                                                            | <img src=\"imgs/kernel_gaussian_blur_approximation_5.svg\" /> |  <img src=\"imgs/kernel_gaussian_blur_approximation_5_result.png\" /> |\n",
    "|  Unsharp Masking (5 x 5) Based on Gaussian Blur      | <img src=\"imgs/kernel_unsharp_masking.svg\" />           | <img src=\"imgs/kernel_unsharp_masking_result.png\" />                |\n",
    "\n",
    "\n",
    "- Note: Unsharp Masking - 5 × 5 - Based on Gaussian blur with amount as 1 and threshold as 0 (with no image mask)\n",
    "- The above are just a few examples of effects achievable by convolving kernels and images. \n",
    "- Origin: \n",
    "  - The origin is the position of the kernel which is above (conceptually) the current output pixel. \n",
    "  - This could be outside of the actual kernel, though usually it corresponds to one of the kernel elements. \n",
    "  - For a symmetric kernel, the origin is usually the center element. \n",
    "\n",
    "### Convolution\n",
    "- Convolution is the process of adding each element of the image to its local neighbors, weighted by the kernel. \n",
    "- This is related to a form of mathematical convolution. \n",
    "- It should be noted that the matrix operation being performed - convolution - is not traditional matrix multiplication, despite being similarly denoted by *.\n",
    "- For example, if we have two three-by-three matrices, the first a kernel, and the second an image piece, convolution is the process of flipping both the rows and columns of the kernel and then multiplying locally similar entries and summing. \n",
    "- The element at coordinates [2, 2] (that is, the central element) of the resulting image would be a weighted combination of all the entries of the image matrix, with weights given by the kernel:\n",
    "\n",
    "<img src=\"imgs/convolution.svg\" />\n",
    "\n",
    "- The other entries would be similarly weighted, where we position the center of the kernel on each of the boundary points of the image, and compute a weighted sum.\n",
    "- The values of a given pixel in the output image are calculated by multiplying each kernel value by the corresponding input image pixel values. \n",
    "- This can be described algorithmically with the following pseudo-code: \n",
    "\n",
    "for each image row in input image:\n",
    "   for each pixel in image row:\n",
    "\n",
    "      set accumulator to zero\n",
    "\n",
    "      for each kernel row in kernel:\n",
    "         for each element in kernel row:\n",
    "\n",
    "            if element position  corresponding* to pixel position then\n",
    "               multiply element value  corresponding* to pixel value\n",
    "               add result to accumulator\n",
    "            endif\n",
    "\n",
    "      set output image pixel to accumulator\n",
    "      \n",
    "\n",
    "- If the kernel is symmetric then place the center (origin) of kernel on the current pixel. \n",
    "- Then kernel will be overlapped with neighboring pixels too. \n",
    "- Now multiply each kernel element with the pixel value it overlapped with and add all the obtained values. \n",
    "- Resultant value will be the value for the current pixel that is overlapped with the center of the kernel.\n",
    "- If the kernel is not symmetric, it has to be flipped both around its horizontal and vertical axis before calculating the convolution as above.\n",
    "- Edge Handling: Kernel convolution usually requires values from pixels outside of the image boundaries. There are a variety of methods for handling image edges.\n",
    "  - Extend: The nearest border pixels are conceptually extended as far as necessary to provide values for the convolution. Corner pixels are extended in 90° wedges. Other edge pixels are extended in lines.\n",
    "  - Wrap: The image is conceptually wrapped (or tiled) and values are taken from the opposite edge or corner.\n",
    "  - Mirror: The image is conceptually mirrored at the edges. For example, attempting to read a pixel 3 units outside an edge reads one 3 units inside the edge instead.\n",
    "  - Crop: Any pixel in the output image which would require values from beyond the edge is skipped. This method can result in the output image being slightly smaller, with the edges having been cropped.\n",
    "  - Kernel Crop: Any pixel in the kernel that extends past the input image isn't used and the normalizing is adjusted to compensate.\n",
    "\n",
    "- Normalization: defined as the division of each element in the kernel by the sum of all kernel elements, so that the sum of the elements of a normalized kernel is one. This will ensure the average pixel in the modified image is as bright as the average pixel in the original image. \n",
    "\n",
    "<img src=\"imgs/Extend_Edge-Handling.png\" />\n",
    "\n",
    "### Filtering\n",
    "- Digital filters are used to blur and sharpen digital images. \n",
    "- Filtering can be performed in the spatial domain by convolution with specifically designed kernels (filter array), or in the frequency (Fourier) domain by masking specific frequency regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height:  300\n",
      "Width:  500\n"
     ]
    }
   ],
   "source": [
    "# Basic Geometric Transformations\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"img/red_panda.jpg\")\n",
    "rows, cols, ch = img.shape\n",
    " \n",
    "print(\"Height: \", rows)\n",
    "print(\"Width: \", cols)\n",
    " \n",
    "scaled_img = cv2.resize(img, None, fx=1/2, fy=1/2)\n",
    " \n",
    "matrix_t = np.float32([[1, 0, -100], [0, 1, -30]])\n",
    "translated_img = cv2.warpAffine(img, matrix_t, (cols, rows))\n",
    " \n",
    "matrix_r = cv2.getRotationMatrix2D((cols/2, rows/2), 90, 0.5)\n",
    "rotated_img = cv2.warpAffine(img, matrix_r, (cols, rows))\n",
    " \n",
    "cv2.imshow(\"Original image\", img)\n",
    "cv2.imshow(\"Scaled image\", scaled_img)\n",
    "cv2.imshow(\"Translated image\", translated_img)\n",
    "cv2.imshow(\"Rotated image\", rotated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective Transformation\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    " \n",
    "    cv2.circle(frame, (155, 120), 5, (0, 0, 255), -1)\n",
    "    cv2.circle(frame, (480, 120), 5, (0, 0, 255), -1)\n",
    "    cv2.circle(frame, (20, 475), 5, (0, 0, 255), -1)\n",
    "    cv2.circle(frame, (620, 475), 5, (0, 0, 255), -1)\n",
    " \n",
    "    pts1 = np.float32([[155, 120], [480, 120], [20, 475], [620, 475]])\n",
    "    pts2 = np.float32([[0, 0], [500, 0], [0, 600], [500, 600]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    " \n",
    "    result = cv2.warpPerspective(frame, matrix, (500, 600))\n",
    " \n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Perspective transformation\", result)\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine Transformation\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"img/grid.jpg\")\n",
    "rows, cols, ch = img.shape\n",
    " \n",
    "cv2.circle(img, (83, 90), 5, (0, 0, 255), -1)\n",
    "cv2.circle(img, (447, 90), 5, (0, 0, 255), -1)\n",
    "cv2.circle(img, (83, 472), 5, (0, 0, 255), -1)\n",
    " \n",
    "pts1 = np.float32([[83, 90], [447, 90], [83, 472]])\n",
    "pts2 = np.float32([[0, 0], [447, 90], [150, 472]])\n",
    " \n",
    "matrix = cv2.getAffineTransform(pts1, pts2)\n",
    "result = cv2.warpAffine(img, matrix, (cols, rows))\n",
    " \n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Affine transformation\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Thresholding\n",
    "In the previous section, we used a global value as threshold value. But it may not be good in all the conditions where image has different lighting conditions in different areas. In that case, we go for adaptive thresholding. In this, the algorithm calculate the threshold for a small regions of the image. So we get different thresholds for different regions of the same image and it gives us better results for images with varying illumination.\n",
    "\n",
    "It has three ‘special’ input params and only one output argument.\n",
    "\n",
    "Adaptive Method - It decides how thresholding value is calculated.\n",
    "\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C : threshold value is the mean of neighbourhood area.\n",
    "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window.\n",
    "\n",
    "Block Size - It decides the size of neighbourhood area.\n",
    "\n",
    "C - It is just a constant which is subtracted from the mean or weighted mean calculated.\n",
    "\n",
    "The mean is the average of the numbers. It is easy to calculate: add up all the numbers, then divide by how many numbers there are. In other words it is the sum divided by the count\n",
    "\n",
    "To use the formula - Gaussian Weighted Sum:\n",
    "\n",
    "    Multiply the numbers in your data set by the weights.\n",
    "    Add the numbers in Step 1 up. Set this number aside for a moment.\n",
    "    Add up all of the weights.\n",
    "    Divide the numbers you found in Step 2 by the number you found in Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Thresholding\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"img/book_page.jpg\")\n",
    "\n",
    "_, threshold = cv2.threshold(img, 155, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "mean_c = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 12)\n",
    "gaus = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 12)\n",
    "\n",
    "cv2.imshow(\"Img\", img)\n",
    "cv2.imshow(\"Binary threshold\", threshold)\n",
    "cv2.imshow(\"Mean C\", mean_c)\n",
    "cv2.imshow(\"Gaussian\", gaus)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing Images\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# img = cv2.imread(\"img/early_1800.jpg\")\n",
    "# img = cv2.imread(\"img/balloons_noisy.png\")\n",
    "img = cv2.imread(\"img/carpet.jpg\")\n",
    "# img = cv2.imread(\"img/lake.jpg\")\n",
    " \n",
    "averaging = cv2.blur(img, (21, 21))\n",
    "gaussian = cv2.GaussianBlur(img, (21, 21), 0)\n",
    "median = cv2.medianBlur(img, 5)\n",
    "bilateral = cv2.bilateralFilter(img, 9, 350, 350)\n",
    " \n",
    "cv2.imshow(\"Original image\", img)\n",
    "cv2.imshow(\"Averaging\", averaging)\n",
    "cv2.imshow(\"Gaussian\", gaussian)\n",
    "cv2.imshow(\"Median\", median)\n",
    "cv2.imshow(\"Bilateral\", bilateral)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Morphological Transformations\n",
    "# Remove Noise from an image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"img/balls.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "# img = cv2.imread(\"img/orange.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 250, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# in dilation, wholes smaller than kernel size will not be shown\n",
    "# test different kernel sizes\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Fill the wholes inside the object\n",
    "dilation = cv2.dilate(mask, kernel)\n",
    "\n",
    "# Removes noise around the object\n",
    "# used mainly when we want to separate objects\n",
    "# In balls example, some balls are connected to others\n",
    "# using erosion, we can easily separate different balls\n",
    "# iterations - how many times using the kernel we iterate over the image\n",
    "erosion = cv2.erode(mask, kernel, iterations=6)\n",
    " \n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.imshow(\"Dilation\", dilation)\n",
    "cv2.imshow(\"Erosion\", erosion)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realtime Video Morphological Transformation\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    " \n",
    "cv2.createTrackbar(\"L - H\", \"Trackbars\", 0, 179, nothing)\n",
    "cv2.createTrackbar(\"L - S\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"L - V\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"U - H\", \"Trackbars\", 179, 179, nothing)\n",
    "cv2.createTrackbar(\"U - S\", \"Trackbars\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"U - V\", \"Trackbars\", 255, 255, nothing)\n",
    " \n",
    " \n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    " \n",
    "    l_h = cv2.getTrackbarPos(\"L - H\", \"Trackbars\")\n",
    "    l_s = cv2.getTrackbarPos(\"L - S\", \"Trackbars\")\n",
    "    l_v = cv2.getTrackbarPos(\"L - V\", \"Trackbars\")\n",
    "    u_h = cv2.getTrackbarPos(\"U - H\", \"Trackbars\")\n",
    "    u_s = cv2.getTrackbarPos(\"U - S\", \"Trackbars\")\n",
    "    u_v = cv2.getTrackbarPos(\"U - V\", \"Trackbars\")\n",
    " \n",
    "    lower_blue = np.array([l_h, l_s, l_v])\n",
    "    upper_blue = np.array([u_h, u_s, u_v])\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    " \n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    erosion = cv2.erode(mask, kernel)\n",
    "    dilation = cv2.dilate(mask, kernel)\n",
    " \n",
    "    opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    " \n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    " \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"erosion\", erosion)\n",
    "    cv2.imshow(\"dilation\", dilation)\n",
    "    cv2.imshow(\"Opening\", opening)\n",
    "    cv2.imshow(\"Closing\", closing)\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Detection\n",
    "\n",
    "# Sharp change in color intensity / value\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"img/white_panda.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.GaussianBlur(img, (11, 11), 0) # To remove noise from images\n",
    "# You can try the following algos, once with, and once without\n",
    "\n",
    "# Use change of contrast\n",
    "# First, Horizontally\n",
    "# Then, Vertically\n",
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0) # 1 0 -> X Axis\n",
    "sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1) # 0 1 -> Y Axis\n",
    " \n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=5) # Try different kernel sizes\n",
    "# Try different blur values with different kernel sizes\n",
    " \n",
    "canny = cv2.Canny(img, 100, 150) # 100 -> Threshold, below it non edges\n",
    "# 150 above it are edges\n",
    " \n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Sobelx\", sobelx) # Poor - with noise\n",
    "cv2.imshow(\"Sobely\", sobely)\n",
    "cv2.imshow(\"Laplacian\", laplacian)\n",
    "cv2.imshow(\"Canny\", canny)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realtime Video Edge Detection\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    " \n",
    "    laplacian = cv2.Laplacian(blurred_frame, cv2.CV_64F)\n",
    "#     canny = cv2.Canny(blurred_frame, 100, 150)\n",
    "    canny = cv2.Canny(blurred_frame, 10, 50)\n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Laplacian\", laplacian)\n",
    "    cv2.imshow(\"Canny\", canny)\n",
    " \n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and Draw Contours\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(blurred_frame, cv2.COLOR_BGR2HSV)\n",
    " \n",
    "    lower_blue = np.array([38, 86, 0])\n",
    "    upper_blue = np.array([121, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    " \n",
    "    _, contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    " \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    " \n",
    "        if area > 5000:\n",
    "            cv2.drawContours(frame, contour, -1, (0, 255, 0), 3)\n",
    " \n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Matching\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"img/simpsons.jpg\")\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread(\"img/barts_face.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "w, h = template.shape[::-1]\n",
    " \n",
    "result = cv2.matchTemplate(gray_img, template, cv2.TM_CCOEFF_NORMED)\n",
    "loc = np.where(result >= 0.4)\n",
    " \n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0, 255, 0), 3)\n",
    " \n",
    " \n",
    "cv2.imshow(\"img\", img)\n",
    " \n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SKIP THIS DEMO NOW\n",
    "\n",
    "# Realtime Video Template Matching\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "template = cv2.imread(\"img/dasani.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    res = cv2.matchTemplate(gray_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "    loc = np.where(res >= 0.7)\n",
    " \n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv2.rectangle(frame, pt, (pt[0] + w, pt[1] + h), (0, 255, 0), 3)\n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    " \n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines Detection\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"img/lines.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 75, 150)\n",
    " \n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 30, maxLineGap=250)\n",
    " \n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    " \n",
    "cv2.imshow(\"Edges\", edges)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines Detection - Video\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "video = cv2.VideoCapture(\"vid/road_car_view.mp4\")\n",
    " \n",
    "while True:\n",
    "    ret, orig_frame = video.read()\n",
    "    if not ret:\n",
    "        video = cv2.VideoCapture(\"vid/road_car_view.mp4\")\n",
    "        continue\n",
    " \n",
    "    frame = cv2.GaussianBlur(orig_frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    low_yellow = np.array([18, 94, 140])\n",
    "    up_yellow = np.array([48, 255, 255])\n",
    "    mask = cv2.inRange(hsv, low_yellow, up_yellow)\n",
    "    edges = cv2.Canny(mask, 75, 150)\n",
    " \n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, maxLineGap=50)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    " \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"edges\", edges)\n",
    " \n",
    "    key = cv2.waitKey(25)\n",
    "    if key == 27:\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corners Detection\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"img/squares.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "corners = cv2.goodFeaturesToTrack(gray, 150, 0.8, 5)\n",
    "corners = np.int0(corners)\n",
    " \n",
    "for corner in corners:\n",
    "    x, y = corner.ravel()\n",
    "    cv2.circle(img, (x, y), 5, (0, 0, 255), -1)\n",
    " \n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corners Detection - Realtime\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.createTrackbar(\"quality\", \"Frame\", 1, 100, nothing)\n",
    " \n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    quality = cv2.getTrackbarPos(\"quality\", \"Frame\")\n",
    "    quality = quality / 100 if quality > 0 else 0.01\n",
    "    corners = cv2.goodFeaturesToTrack(gray, 100, quality, 20)\n",
    " \n",
    "    if corners is not None:\n",
    "        corners = np.int0(corners)\n",
    " \n",
    "        for corner in corners:\n",
    "            x, y = corner.ravel()\n",
    "            cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
